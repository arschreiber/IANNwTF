{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-19 23:16:49.348890: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-19 23:16:49.525419: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-02-19 23:16:49.525438: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-02-19 23:16:50.256620: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-19 23:16:50.256686: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-19 23:16:50.256694: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import sentencepiece as sp\n",
    "import tensorflow as tf\n",
    "import tensorflow_text as text\n",
    "import math\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"bible.txt\", \"r\") as f:\n",
    "    bible_input =  f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(data):\n",
    "    data = data.lower()\n",
    "    data = re.sub(\"\\d+:\\d+ \", \"\", data)\n",
    "    data = data.replace(\"\\n\\n\", \"\\n\")\n",
    "    data = data.replace(\"\\n\\n\", \"\\n\")\n",
    "    data = re.sub(\" +\", \" \", data)\n",
    "    \n",
    "    special_characters = \",.:;!?\"\n",
    "    for c in special_characters:\n",
    "        data = data.replace(c, \"\")\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_data = prepare_data(bible_input)\n",
    "\n",
    "with open(\"bible_prep.txt\", \"w\") as f:\n",
    "    f.write(preprocessed_data)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sentencepiece_trainer.cc(77) LOG(INFO) Starts training with : \n",
      "trainer_spec {\n",
      "  input: bible_prep.txt\n",
      "  input_format: \n",
      "  model_prefix: tokenizer\n",
      "  model_type: UNIGRAM\n",
      "  vocab_size: 2000\n",
      "  self_test_sample_size: 0\n",
      "  character_coverage: 0.9995\n",
      "  input_sentence_size: 0\n",
      "  shuffle_input_sentence: 1\n",
      "  seed_sentencepiece_size: 1000000\n",
      "  shrinking_factor: 0.75\n",
      "  max_sentence_length: 4192\n",
      "  num_threads: 16\n",
      "  num_sub_iterations: 2\n",
      "  max_sentencepiece_length: 16\n",
      "  split_by_unicode_script: 1\n",
      "  split_by_number: 1\n",
      "  split_by_whitespace: 1\n",
      "  split_digits: 0\n",
      "  treat_whitespace_as_suffix: 0\n",
      "  allow_whitespace_only_pieces: 0\n",
      "  required_chars: \n",
      "  byte_fallback: 0\n",
      "  vocabulary_output_piece_score: 1\n",
      "  train_extremely_large_corpus: 0\n",
      "  hard_vocab_limit: 1\n",
      "  use_all_vocab: 0\n",
      "  unk_id: 0\n",
      "  bos_id: 1\n",
      "  eos_id: 2\n",
      "  pad_id: -1\n",
      "  unk_piece: <unk>\n",
      "  bos_piece: <s>\n",
      "  eos_piece: </s>\n",
      "  pad_piece: <pad>\n",
      "  unk_surface:  ‚Åá \n",
      "  enable_differential_privacy: 0\n",
      "  differential_privacy_noise_level: 0\n",
      "  differential_privacy_clipping_threshold: 0\n",
      "}\n",
      "normalizer_spec {\n",
      "  name: nmt_nfkc\n",
      "  add_dummy_prefix: 1\n",
      "  remove_extra_whitespaces: 1\n",
      "  escape_whitespaces: 1\n",
      "  normalization_rule_tsv: \n",
      "}\n",
      "denormalizer_spec {}\n",
      "trainer_interface.cc(350) LOG(INFO) SentenceIterator is not specified. Using MultiFileSentenceIterator.\n",
      "trainer_interface.cc(181) LOG(INFO) Loading corpus: bible_prep.txt\n",
      "trainer_interface.cc(406) LOG(INFO) Loaded all 74644 sentences\n",
      "trainer_interface.cc(422) LOG(INFO) Adding meta_piece: <unk>\n",
      "trainer_interface.cc(422) LOG(INFO) Adding meta_piece: <s>\n",
      "trainer_interface.cc(422) LOG(INFO) Adding meta_piece: </s>\n",
      "trainer_interface.cc(427) LOG(INFO) Normalizing sentences...\n",
      "trainer_interface.cc(536) LOG(INFO) all chars count=4018481\n",
      "trainer_interface.cc(547) LOG(INFO) Done: 99.9542% characters are covered.\n",
      "trainer_interface.cc(557) LOG(INFO) Alphabet size=28\n",
      "trainer_interface.cc(558) LOG(INFO) Final character coverage=0.999542\n",
      "trainer_interface.cc(590) LOG(INFO) Done! preprocessed 74644 sentences.\n",
      "unigram_model_trainer.cc(146) LOG(INFO) Making suffix array...\n",
      "unigram_model_trainer.cc(150) LOG(INFO) Extracting frequent sub strings...\n",
      "unigram_model_trainer.cc(201) LOG(INFO) Initialized 36859 seed sentencepieces\n",
      "trainer_interface.cc(596) LOG(INFO) Tokenizing input sentences with whitespace: 74644\n",
      "trainer_interface.cc(607) LOG(INFO) Done! 13084\n",
      "unigram_model_trainer.cc(491) LOG(INFO) Using 13084 sentences for EM training\n",
      "unigram_model_trainer.cc(507) LOG(INFO) EM sub_iter=0 size=13699 obj=8.05885 num_tokens=21243 num_tokens/piece=1.5507\n",
      "unigram_model_trainer.cc(507) LOG(INFO) EM sub_iter=1 size=10198 obj=6.35123 num_tokens=21233 num_tokens/piece=2.08207\n",
      "unigram_model_trainer.cc(507) LOG(INFO) EM sub_iter=0 size=7648 obj=6.29369 num_tokens=23444 num_tokens/piece=3.06538\n",
      "unigram_model_trainer.cc(507) LOG(INFO) EM sub_iter=1 size=7646 obj=6.28478 num_tokens=23446 num_tokens/piece=3.06644\n",
      "unigram_model_trainer.cc(507) LOG(INFO) EM sub_iter=0 size=5733 obj=6.36173 num_tokens=27679 num_tokens/piece=4.82801\n",
      "unigram_model_trainer.cc(507) LOG(INFO) EM sub_iter=1 size=5733 obj=6.34454 num_tokens=27680 num_tokens/piece=4.82819\n",
      "unigram_model_trainer.cc(507) LOG(INFO) EM sub_iter=0 size=4299 obj=6.46766 num_tokens=32219 num_tokens/piece=7.49453\n",
      "unigram_model_trainer.cc(507) LOG(INFO) EM sub_iter=1 size=4299 obj=6.4436 num_tokens=32220 num_tokens/piece=7.49477\n",
      "unigram_model_trainer.cc(507) LOG(INFO) EM sub_iter=0 size=3224 obj=6.6164 num_tokens=36658 num_tokens/piece=11.3703\n",
      "unigram_model_trainer.cc(507) LOG(INFO) EM sub_iter=1 size=3224 obj=6.58653 num_tokens=36660 num_tokens/piece=11.371\n",
      "unigram_model_trainer.cc(507) LOG(INFO) EM sub_iter=0 size=2418 obj=6.81561 num_tokens=40805 num_tokens/piece=16.8755\n",
      "unigram_model_trainer.cc(507) LOG(INFO) EM sub_iter=1 size=2418 obj=6.77718 num_tokens=40811 num_tokens/piece=16.878\n",
      "unigram_model_trainer.cc(507) LOG(INFO) EM sub_iter=0 size=2200 obj=6.85122 num_tokens=41946 num_tokens/piece=19.0664\n",
      "unigram_model_trainer.cc(507) LOG(INFO) EM sub_iter=1 size=2200 obj=6.84007 num_tokens=41947 num_tokens/piece=19.0668\n",
      "trainer_interface.cc(685) LOG(INFO) Saving model: tokenizer.model\n",
      "trainer_interface.cc(697) LOG(INFO) Saving vocabs: tokenizer.vocab\n"
     ]
    }
   ],
   "source": [
    "VOCAB_SIZE = 2000\n",
    "\n",
    "sp.SentencePieceTrainer.train(input=\"bible_prep.txt\", model_prefix=\"tokenizer\", model_type=\"unigram\", vocab_size=VOCAB_SIZE)\n",
    "sp_model = tf.io.gfile.GFile(\"tokenizer.model\", \"rb\").read()\n",
    "tokenizer = text.SentencepieceTokenizer(sp_model)\n",
    "tokens = tokenizer.tokenize(preprocessed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 32\n",
    "sliding_window = text.sliding_window(data=tokens, width=m+1)\n",
    "\n",
    "input_data = sliding_window[:, :m]\n",
    "input_ds = tf.data.Dataset.from_tensor_slices(input_data)\n",
    "\n",
    "target_data = sliding_window[:, 1:]\n",
    "target_ds = tf.data.Dataset.from_tensor_slices(target_data)\n",
    "dataset = tf.data.Dataset.zip((input_ds, target_ds))\n",
    "dataset = dataset.shuffle(1024).batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "train_size = math.floor(len(dataset) * 0.8)\n",
    "test_size = math.floor(len(dataset) * 0.2)\n",
    "train_dataset = dataset.take(train_size)\n",
    "test_dataset = dataset.skip(train_size).take(test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Embedding(tf.keras.layers.Layer):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.embed_token = tf.keras.layers.Embedding(VOCAB_SIZE, 64)\n",
    "        self.embed_position = tf.keras.layers.Embedding(m, 64)\n",
    "\n",
    "    def call(self, input):\n",
    "        indices = tf.range(0, input.shape[1])\n",
    "        token_embedding = self.embed_token(input)\n",
    "        position_embedding = self.embed_position(indices)\n",
    "        return token_embedding + position_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock(tf.keras.layers.Layer):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.mha = tf.keras.layers.MultiHeadAttention(4, 64)\n",
    "        self.dense1 = tf.keras.layers.Dense(64, activation='relu')\n",
    "        self.dense2 = tf.keras.layers.Dense(64)\n",
    "        self.dropout1 = tf.keras.layers.Dropout(0.1)\n",
    "        self.dropout2 = tf.keras.layers.Dropout(0.1)\n",
    "        self.layer_normalization1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layer_normalization2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "    def call(self, input, training):\n",
    "        x = self.mha(input, input, use_causal_mask=True)\n",
    "        x = self.dropout1(x, training=training)\n",
    "        x = tf.math.add(x, input)\n",
    "        x = self.layer_normalization1(x)\n",
    "        y = self.dense1(x)\n",
    "        y = self.dense2(y)\n",
    "        y = self.dropout2(y)\n",
    "        x = tf.math.add(x, y)\n",
    "        return self.layer_normalization2(x)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(tf.keras.Model):\n",
    "    def __init__(self, tokenizer):\n",
    "        super().__init__()\n",
    "\n",
    "        self.optimizer = tf.keras.optimizers.Adam(learning_rate = 0.001)\n",
    "        self.loss_function = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "        self.tokenizer = tokenizer\n",
    "        \n",
    "        self.metrics_list = [\n",
    "            tf.keras.metrics.SparseCategoricalCrossentropy(name=\"loss\"),\n",
    "            tf.keras.metrics.CategoricalAccuracy(name=\"accuracy\")\n",
    "        ]\n",
    "        self.embedding = Embedding()\n",
    "        self.transformer_block = TransformerBlock()\n",
    "        self.out = tf.keras.layers.Dense(2000)\n",
    "\n",
    "    def call(self, input, training):\n",
    "        x = self.embedding(input)\n",
    "        x = self.transformer_block(x)\n",
    "        return self.out(x)\n",
    "    \n",
    "    def reset_metrics(self):\n",
    "        for metric in self.metrics:\n",
    "            metric.reset_states()\n",
    "\n",
    "    def train_step(self, data):\n",
    "        input, target = data\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            output = self(input, training=True)\n",
    "            loss = self.loss_function(target, output)\n",
    "\n",
    "        gradients = tape.gradient(loss, self.trainable_variables)\n",
    "        self.optimizer.apply_gradients(zip(gradients, self.trainable_variables))\n",
    "        for metric in self.metrics_list:\n",
    "            metric.update_state(target, output)\n",
    "\n",
    "        return {m.name : m.result() for m in self.metrics}\n",
    "    \n",
    "    def generate_text(self, prompt, output_length, top_k):\n",
    "        prompt = self.tokenizer.tokenize(prompt)\n",
    "        prompt = tf.expand_dims(prompt, 0)\n",
    "\n",
    "        while prompt.shape[1] < output_length:\n",
    "            paddings = tf.constant([[0, 0],\n",
    "                        [max(self.sequence_length - prompt.shape[1], 0), 0]])\n",
    "      \n",
    "        padded_prompt = tf.pad(prompt, paddings, constant_values=-1)\n",
    "        logits = self(padded_prompt)\n",
    "        top_logits, top_indices = tf.math.top_k(logits, k=top_k, sorted=True)\n",
    "        next_token = tf.random.categorical(top_logits, 1)\n",
    "        next_token = top_indices[0, tf.squeeze(next_token)]\n",
    "        next_token = tf.reshape(next_token, (1,1))\n",
    "        prompt = tf.concat([prompt, next_token], axis = 1)\n",
    "        \n",
    "        return self.tokeniser.detokenize(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop(model, train_ds):\n",
    "    for e in range(100):\n",
    "        print(f\"Epoch {e}:\")\n",
    "\n",
    "        for data in tqdm.tqdm(train_ds):\n",
    "            metrics = model.train_step(data)\n",
    "\n",
    "        for metric in model.metrics:\n",
    "            print(f\"{metric.name}: {metric.result()}\")\n",
    "\n",
    "        model.reset_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 18/23115 [00:02<50:15,  7.66it/s] \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/arthur/studium/ann/repo/hw11/hw11.ipynb Cell 11\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/arthur/studium/ann/repo/hw11/hw11.ipynb#X51sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m model \u001b[39m=\u001b[39m Transformer(tokenizer)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/arthur/studium/ann/repo/hw11/hw11.ipynb#X51sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m training_loop(model, train_dataset)\n",
      "\u001b[1;32m/home/arthur/studium/ann/repo/hw11/hw11.ipynb Cell 11\u001b[0m in \u001b[0;36mtraining_loop\u001b[0;34m(model, train_ds)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/arthur/studium/ann/repo/hw11/hw11.ipynb#X51sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mEpoch \u001b[39m\u001b[39m{\u001b[39;00me\u001b[39m}\u001b[39;00m\u001b[39m:\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/arthur/studium/ann/repo/hw11/hw11.ipynb#X51sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mfor\u001b[39;00m data \u001b[39min\u001b[39;00m tqdm\u001b[39m.\u001b[39mtqdm(train_ds):\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/arthur/studium/ann/repo/hw11/hw11.ipynb#X51sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     metrics \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mtrain_step(data)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/arthur/studium/ann/repo/hw11/hw11.ipynb#X51sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mfor\u001b[39;00m metric \u001b[39min\u001b[39;00m model\u001b[39m.\u001b[39mmetrics:\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/arthur/studium/ann/repo/hw11/hw11.ipynb#X51sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mmetric\u001b[39m.\u001b[39mname\u001b[39m}\u001b[39;00m\u001b[39m: \u001b[39m\u001b[39m{\u001b[39;00mmetric\u001b[39m.\u001b[39mresult()\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;32m/home/arthur/studium/ann/repo/hw11/hw11.ipynb Cell 11\u001b[0m in \u001b[0;36mTransformer.train_step\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/arthur/studium/ann/repo/hw11/hw11.ipynb#X51sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m(\u001b[39minput\u001b[39m, training\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/arthur/studium/ann/repo/hw11/hw11.ipynb#X51sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m     loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mloss_function(target, output)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/arthur/studium/ann/repo/hw11/hw11.ipynb#X51sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m gradients \u001b[39m=\u001b[39m tape\u001b[39m.\u001b[39;49mgradient(loss, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrainable_variables)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/arthur/studium/ann/repo/hw11/hw11.ipynb#X51sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptimizer\u001b[39m.\u001b[39mapply_gradients(\u001b[39mzip\u001b[39m(gradients, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrainable_variables))\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/arthur/studium/ann/repo/hw11/hw11.ipynb#X51sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m \u001b[39mfor\u001b[39;00m metric \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmetrics_list:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/backprop.py:1112\u001b[0m, in \u001b[0;36mGradientTape.gradient\u001b[0;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[1;32m   1106\u001b[0m   output_gradients \u001b[39m=\u001b[39m (\n\u001b[1;32m   1107\u001b[0m       composite_tensor_gradient\u001b[39m.\u001b[39mget_flat_tensors_for_gradients(\n\u001b[1;32m   1108\u001b[0m           output_gradients))\n\u001b[1;32m   1109\u001b[0m   output_gradients \u001b[39m=\u001b[39m [\u001b[39mNone\u001b[39;00m \u001b[39mif\u001b[39;00m x \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m ops\u001b[39m.\u001b[39mconvert_to_tensor(x)\n\u001b[1;32m   1110\u001b[0m                       \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m output_gradients]\n\u001b[0;32m-> 1112\u001b[0m flat_grad \u001b[39m=\u001b[39m imperative_grad\u001b[39m.\u001b[39;49mimperative_grad(\n\u001b[1;32m   1113\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_tape,\n\u001b[1;32m   1114\u001b[0m     flat_targets,\n\u001b[1;32m   1115\u001b[0m     flat_sources,\n\u001b[1;32m   1116\u001b[0m     output_gradients\u001b[39m=\u001b[39;49moutput_gradients,\n\u001b[1;32m   1117\u001b[0m     sources_raw\u001b[39m=\u001b[39;49mflat_sources_raw,\n\u001b[1;32m   1118\u001b[0m     unconnected_gradients\u001b[39m=\u001b[39;49munconnected_gradients)\n\u001b[1;32m   1120\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_persistent:\n\u001b[1;32m   1121\u001b[0m   \u001b[39m# Keep track of watched variables before setting tape to None\u001b[39;00m\n\u001b[1;32m   1122\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_watched_variables \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tape\u001b[39m.\u001b[39mwatched_variables()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/imperative_grad.py:67\u001b[0m, in \u001b[0;36mimperative_grad\u001b[0;34m(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m:\n\u001b[1;32m     64\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m     65\u001b[0m       \u001b[39m\"\u001b[39m\u001b[39mUnknown value for unconnected_gradients: \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m unconnected_gradients)\n\u001b[0;32m---> 67\u001b[0m \u001b[39mreturn\u001b[39;00m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_TapeGradient(\n\u001b[1;32m     68\u001b[0m     tape\u001b[39m.\u001b[39;49m_tape,  \u001b[39m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m     69\u001b[0m     target,\n\u001b[1;32m     70\u001b[0m     sources,\n\u001b[1;32m     71\u001b[0m     output_gradients,\n\u001b[1;32m     72\u001b[0m     sources_raw,\n\u001b[1;32m     73\u001b[0m     compat\u001b[39m.\u001b[39;49mas_str(unconnected_gradients\u001b[39m.\u001b[39;49mvalue))\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/backprop.py:157\u001b[0m, in \u001b[0;36m_gradient_function\u001b[0;34m(op_name, attr_tuple, num_inputs, inputs, outputs, out_grads, skip_input_indices, forward_pass_name_scope)\u001b[0m\n\u001b[1;32m    155\u001b[0m     gradient_name_scope \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m forward_pass_name_scope \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m/\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    156\u001b[0m   \u001b[39mwith\u001b[39;00m ops\u001b[39m.\u001b[39mname_scope(gradient_name_scope):\n\u001b[0;32m--> 157\u001b[0m     \u001b[39mreturn\u001b[39;00m grad_fn(mock_op, \u001b[39m*\u001b[39;49mout_grads)\n\u001b[1;32m    158\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    159\u001b[0m   \u001b[39mreturn\u001b[39;00m grad_fn(mock_op, \u001b[39m*\u001b[39mout_grads)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/ops/math_grad.py:1676\u001b[0m, in \u001b[0;36m_SelectGradV2\u001b[0;34m(op, grad)\u001b[0m\n\u001b[1;32m   1673\u001b[0m gx \u001b[39m=\u001b[39m array_ops\u001b[39m.\u001b[39mreshape(gx, x_shape)\n\u001b[1;32m   1675\u001b[0m gy \u001b[39m=\u001b[39m array_ops\u001b[39m.\u001b[39mwhere_v2(c, zeros, grad)\n\u001b[0;32m-> 1676\u001b[0m y_shape \u001b[39m=\u001b[39m array_ops\u001b[39m.\u001b[39;49mshape(y)\n\u001b[1;32m   1677\u001b[0m \u001b[39m# Reduce away broadcasted leading dims.\u001b[39;00m\n\u001b[1;32m   1678\u001b[0m reduce_y, _ \u001b[39m=\u001b[39m gen_array_ops\u001b[39m.\u001b[39mbroadcast_gradient_args(y_shape, output_shape)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/util/dispatch.py:1176\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1174\u001b[0m \u001b[39m# Fallback dispatch system (dispatch v1):\u001b[39;00m\n\u001b[1;32m   1175\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1176\u001b[0m   \u001b[39mreturn\u001b[39;00m dispatch_target(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1177\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mTypeError\u001b[39;00m, \u001b[39mValueError\u001b[39;00m):\n\u001b[1;32m   1178\u001b[0m   \u001b[39m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[1;32m   1179\u001b[0m   \u001b[39m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[1;32m   1180\u001b[0m   result \u001b[39m=\u001b[39m dispatch(op_dispatch_handler, args, kwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/ops/array_ops.py:656\u001b[0m, in \u001b[0;36mshape\u001b[0;34m(input, name, out_type)\u001b[0m\n\u001b[1;32m    632\u001b[0m \u001b[39m@tf_export\u001b[39m(v1\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39mshape\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[1;32m    633\u001b[0m \u001b[39m@dispatch\u001b[39m\u001b[39m.\u001b[39madd_dispatch_support\n\u001b[1;32m    634\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mshape\u001b[39m(\u001b[39minput\u001b[39m, name\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, out_type\u001b[39m=\u001b[39mdtypes\u001b[39m.\u001b[39mint32):\n\u001b[1;32m    635\u001b[0m   \u001b[39m# pylint: disable=redefined-builtin\u001b[39;00m\n\u001b[1;32m    636\u001b[0m   \u001b[39m\"\"\"Returns the shape of a tensor.\u001b[39;00m\n\u001b[1;32m    637\u001b[0m \n\u001b[1;32m    638\u001b[0m \u001b[39m  This operation returns a 1-D integer tensor representing the shape of `input`.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    654\u001b[0m \u001b[39m    A `Tensor` of type `out_type`.\u001b[39;00m\n\u001b[1;32m    655\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 656\u001b[0m   \u001b[39mreturn\u001b[39;00m shape_internal(\u001b[39minput\u001b[39;49m, name, optimize\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, out_type\u001b[39m=\u001b[39;49mout_type)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/ops/array_ops.py:697\u001b[0m, in \u001b[0;36mshape_internal\u001b[0;34m(input, name, optimize, out_type)\u001b[0m\n\u001b[1;32m    695\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m out_type:\n\u001b[1;32m    696\u001b[0m   out_type \u001b[39m=\u001b[39m dtypes\u001b[39m.\u001b[39mint32\n\u001b[0;32m--> 697\u001b[0m \u001b[39mreturn\u001b[39;00m gen_array_ops\u001b[39m.\u001b[39;49mshape(\u001b[39minput\u001b[39;49m, name\u001b[39m=\u001b[39;49mname, out_type\u001b[39m=\u001b[39;49mout_type)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/ops/gen_array_ops.py:9356\u001b[0m, in \u001b[0;36mshape\u001b[0;34m(input, out_type, name)\u001b[0m\n\u001b[1;32m   9354\u001b[0m \u001b[39mif\u001b[39;00m tld\u001b[39m.\u001b[39mis_eager:\n\u001b[1;32m   9355\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 9356\u001b[0m     _result \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_FastPathExecute(\n\u001b[1;32m   9357\u001b[0m       _ctx, \u001b[39m\"\u001b[39;49m\u001b[39mShape\u001b[39;49m\u001b[39m\"\u001b[39;49m, name, \u001b[39minput\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mout_type\u001b[39;49m\u001b[39m\"\u001b[39;49m, out_type)\n\u001b[1;32m   9358\u001b[0m     \u001b[39mreturn\u001b[39;00m _result\n\u001b[1;32m   9359\u001b[0m   \u001b[39mexcept\u001b[39;00m _core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = Transformer(tokenizer)\n",
    "\n",
    "training_loop(model, train_dataset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
