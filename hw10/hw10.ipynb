{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "dd5e9fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import PIL\n",
    "from tensorflow.keras import layers\n",
    "import time\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import re\n",
    "import string\n",
    "import random\n",
    "import tqdm\n",
    "from IPython import display\n",
    "\n",
    "\n",
    "import requests\n",
    "import tensorflow as tf\n",
    "import tensorflow_text as tf_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "59bef50a",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 1024\n",
    "num_ns = 4\n",
    "embedding_dim = 128\n",
    "vocab_size = 1000\n",
    "sequence_length = 10\n",
    "window_size = 4\n",
    "BUFFER_SIZE = 10000\n",
    "buffer_size = 500\n",
    "SEED = random.randint(0, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "09264a6f",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (3070697667.py, line 15)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[83], line 15\u001b[0;36m\u001b[0m\n\u001b[0;31m    vectorize_layer.adapt(text_ds.batch(BATCH_SIZE))\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "#2.1 and 2.2\n",
    "\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "path_to_file = os.path.abspath(\"./\" +'bible.txt')\n",
    "text_ds = tf.data.TextLineDataset(path_to_file).filter(lambda x: tf.cast(tf.strings.length(x), bool))\n",
    "def custom_standardization(input_data):\n",
    "  lowercase = tf.strings.lower(input_data)\n",
    "  return tf.strings.regex_replace(lowercase, '[%s]' % re.escape(string.punctuation), '')\n",
    "\n",
    "vectorize_layer = layers.TextVectorization(\n",
    "    standardize=custom_standardization,\n",
    "    max_tokens=vocab_size,\n",
    "    output_sequence_length=sequence_length)\n",
    "    vectorize_layer.adapt(text_ds.batch(BATCH_SIZE))\n",
    "inverse_vocab = vectorize_layer.get_vocabulary()\n",
    "text_vector_ds = text_ds.batch(BATCH_SIZE).prefetch(AUTOTUNE).map(vectorize_layer).unbatch()\n",
    "sequences = list(text_vector_ds.as_numpy_iterator())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eecce2b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "b62b4032",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_training_data(sequences, window_size, num_ns, vocab_size, seed):\n",
    "  # Elements of each training example are appended to these lists.\n",
    "  targets, contexts, labels = [], [], []\n",
    "\n",
    "  # Build the sampling table for `vocab_size` tokens.\n",
    "  sampling_table = tf.keras.preprocessing.sequence.make_sampling_table(vocab_size)\n",
    "\n",
    "  # Iterate over all sequences (sentences) in the dataset.\n",
    "  for sequence in tqdm.tqdm(sequences):\n",
    "\n",
    "    # Generate positive skip-gram pairs for a sequence (sentence).\n",
    "    positive_skip_grams, _ = tf.keras.preprocessing.sequence.skipgrams(\n",
    "          sequence,\n",
    "          vocabulary_size=vocab_size,\n",
    "          sampling_table=sampling_table,\n",
    "          window_size=window_size,\n",
    "          negative_samples=0)\n",
    "\n",
    "    # Iterate over each positive skip-gram pair to produce training examples\n",
    "    # with a positive context word and negative samples.\n",
    "    for target_word, context_word in positive_skip_grams:\n",
    "      context_class = tf.expand_dims(\n",
    "          tf.constant([context_word], dtype=\"int64\"), 1)\n",
    "      negative_sampling_candidates, _, _ = tf.random.log_uniform_candidate_sampler(\n",
    "          true_classes=context_class,\n",
    "          num_true=1,\n",
    "          num_sampled=num_ns,\n",
    "          unique=True,\n",
    "          range_max=vocab_size,\n",
    "          seed=seed,\n",
    "          name=\"negative_sampling\")\n",
    "\n",
    "      # Build context and label vectors (for one target word)\n",
    "      negative_sampling_candidates = tf.expand_dims(\n",
    "          negative_sampling_candidates, 1)\n",
    "\n",
    "      context = tf.concat([context_class, negative_sampling_candidates], 0)\n",
    "      label = tf.constant([1] + [0]*num_ns, dtype=\"int64\")\n",
    "\n",
    "      # Append each element from the training example to global lists.\n",
    "      targets.append(target_word)\n",
    "      contexts.append(context)\n",
    "      labels.append(label)\n",
    "\n",
    "  return targets, contexts, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "759fcbd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 74644/74644 [00:09<00:00, 8256.18it/s]\n"
     ]
    }
   ],
   "source": [
    "#2.3\n",
    "#Useing the freedom granted in the task to use an alternative implementation of SkipGram\n",
    "#and for that adding a label into the input formation\n",
    "\n",
    "targets, contexts, labels = generate_training_data(sequences=sequences, window_size=2, num_ns=4, vocab_size=vocab_size, seed=SEED)\n",
    "\n",
    "targets = np.array(targets)\n",
    "contexts = np.array(contexts)[:,:,0]\n",
    "labels = np.array(labels)\n",
    "\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices(((targets, contexts), labels))\n",
    "dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n",
    "dataset = dataset.cache().prefetch(BUFFER_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "5e22dcba",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "class Word2Vec(tf.keras.Model):\n",
    "  def __init__(self, vocab_size, embedding_dim):\n",
    "    super(Word2Vec, self).__init__()\n",
    "    self.target_embedding = layers.Embedding(vocab_size,\n",
    "                                      embedding_dim,\n",
    "                                      input_length=1,\n",
    "                                      name=\"w2v_embedding\")\n",
    "    self.context_embedding = layers.Embedding(vocab_size,\n",
    "                                       embedding_dim,\n",
    "                                       input_length=num_ns+1)\n",
    "\n",
    "  def call(self, pair):\n",
    "    target, context = pair\n",
    "    if len(target.shape) == 2:\n",
    "      target = tf.squeeze(target, axis=1)\n",
    "    word_emb = self.target_embedding(target)\n",
    "    context_emb = self.context_embedding(context)\n",
    "    \n",
    "    dots = tf.einsum('be,bce->bc', word_emb, context_emb)\n",
    "    return dots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "22faec2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2.4\n",
    "\n",
    "word2vec = Word2Vec(vocab_size, embedding_dim)\n",
    "word2vec.compile(optimizer='adam', loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "af50e47a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "110/110 [==============================] - 1s 3ms/step - loss: 1.5856 - accuracy: 0.3476\n",
      "Epoch 2/20\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 1.4629 - accuracy: 0.4131\n",
      "Epoch 3/20\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 1.3765 - accuracy: 0.4375\n",
      "Epoch 4/20\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 1.3168 - accuracy: 0.4699\n",
      "Epoch 5/20\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 1.2658 - accuracy: 0.4991\n",
      "Epoch 6/20\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 1.2205 - accuracy: 0.5220\n",
      "Epoch 7/20\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 1.1803 - accuracy: 0.5412\n",
      "Epoch 8/20\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 1.1444 - accuracy: 0.5572\n",
      "Epoch 9/20\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 1.1119 - accuracy: 0.5722\n",
      "Epoch 10/20\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 1.0822 - accuracy: 0.5853\n",
      "Epoch 11/20\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 1.0549 - accuracy: 0.5972\n",
      "Epoch 12/20\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 1.0295 - accuracy: 0.6084\n",
      "Epoch 13/20\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 1.0057 - accuracy: 0.6180\n",
      "Epoch 14/20\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.9834 - accuracy: 0.6275\n",
      "Epoch 15/20\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.9623 - accuracy: 0.6365\n",
      "Epoch 16/20\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.9424 - accuracy: 0.6446\n",
      "Epoch 17/20\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.9236 - accuracy: 0.6525\n",
      "Epoch 18/20\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.9057 - accuracy: 0.6606\n",
      "Epoch 19/20\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.8887 - accuracy: 0.6672\n",
      "Epoch 20/20\n",
      "110/110 [==============================] - 0s 2ms/step - loss: 0.8725 - accuracy: 0.6738\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fd7282f3100>"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#using the loop in the fit-method\n",
    "word2vec.fit(dataset, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "5cbe8392",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 128)\n"
     ]
    }
   ],
   "source": [
    "weights = word2vec.get_layer('w2v_embedding').get_weights()[0]\n",
    "print(weights.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "c27709da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateDistance(position1, position2):\n",
    "    distance = 0\n",
    "    for i in range(0,len(position1)):\n",
    "        distance = distance + (position1[i] - position2[i]) * (position1[i] - position2[i])\n",
    "    return distance\n",
    "\n",
    "def findeNN(index):\n",
    "    if index == 1:\n",
    "        nearest = 2\n",
    "        nearestDistant = calculateDistance(weights[index],weights[0])\n",
    "    else:\n",
    "        nearest = 1\n",
    "        nearestDistant = calculateDistance(weights[index],weights[1])          \n",
    "    i = 0\n",
    "    for postion in weights:\n",
    "        if i != index:\n",
    "            if i != 0:\n",
    "                temp = calculateDistance(weights[index],weights[i])\n",
    "                if nearestDistant > temp:\n",
    "                    nearestDistant = temp\n",
    "                    nearest = i\n",
    "        \n",
    "        i = i+1\n",
    "    return nearest\n",
    "\n",
    "def printNN(string):\n",
    "    for i in range(0,len(inverse_vocab)):\n",
    "        if inverse_vocab[i] == string:\n",
    "            number = i\n",
    "    clostest = inverse_vocab[findeNN(number)]\n",
    "    print(\"for '\" + str(string) + \"' the nearest neighbours is '\" + str(clostest) +\"'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "b471315e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 'he' the nearest neighbours is 'she'\n",
      "for 'father' the nearest neighbours is 'master'\n",
      "for 'water' the nearest neighbours is 'wilderness'\n",
      "for 'old' the nearest neighbours is 'years'\n",
      "for 'strong' the nearest neighbours is 'wine'\n",
      "for 'day' the nearest neighbours is 'year'\n"
     ]
    }
   ],
   "source": [
    "printNN('he')\n",
    "printNN('father')\n",
    "printNN('water')\n",
    "printNN('old')\n",
    "printNN('strong')\n",
    "printNN('day')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d27bffa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bcff6fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "543fd918",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
